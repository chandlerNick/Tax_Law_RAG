{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4d3d2a",
   "metadata": {},
   "source": [
    "# First RAG pipeline\n",
    "\n",
    "This is just so we can get something done. Experiments and improvements will be applied as development continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3883b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Annoy\n",
    "\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Namespace Spec (for lxml)\n",
    "NS = {'uslm': 'http://xml.house.gov/schemas/uslm/1.0',\n",
    "      'xhtml': 'http://www.w3.org/1999/xhtml'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711078dd",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3df9d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ancestor_heading_text(section, tag, ns):\n",
    "    ancestor = section.getparent()\n",
    "    while ancestor is not None:\n",
    "        if ancestor.tag == f\"{{{ns['uslm']}}}{tag}\":\n",
    "            heading = ancestor.find('uslm:heading', namespaces=ns)\n",
    "            return heading.text.strip() if heading is not None else \"\"\n",
    "        ancestor = ancestor.getparent()\n",
    "    return \"\"\n",
    "\n",
    "def parse_sections_with_metadata(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        tree = etree.parse(f)\n",
    "    \n",
    "    sections = tree.findall('.//uslm:section', namespaces=NS)\n",
    "    parsed = []\n",
    "\n",
    "    for section in sections:\n",
    "        heading = section.find('uslm:heading', namespaces=NS)\n",
    "        heading_text = heading.text.strip() if heading is not None else \"\"\n",
    "\n",
    "        # Get all paragraphs (and any nested elements)\n",
    "        content_texts = []\n",
    "        for p in section.findall('.//uslm:p', namespaces=NS):\n",
    "            text = ' '.join(p.itertext()).strip()\n",
    "            if text:\n",
    "                content_texts.append(text)\n",
    "\n",
    "        # Get ancestors: subtitle, chapter, part\n",
    "        subtitle = get_ancestor_heading_text(section, 'subtitle', NS)\n",
    "        chapter = get_ancestor_heading_text(section, 'chapter', NS)\n",
    "        part = get_ancestor_heading_text(section, 'part', NS)\n",
    "\n",
    "        parsed.append({\n",
    "            \"metadata\": {\n",
    "                \"section_head\": heading_text,\n",
    "                \"subtitle\": subtitle,\n",
    "                \"chapter\": chapter,\n",
    "                \"part\": part\n",
    "                },\n",
    "            \"content\": \"\\n\".join(content_texts)\n",
    "        })\n",
    "\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a0719d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = parse_sections_with_metadata(\"./usc26.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a830e28",
   "metadata": {},
   "source": [
    "Ingest & Chunk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3a6cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap in LangChain Document objects\n",
    "documents = [\n",
    "    Document(page_content=d[\"content\"], metadata=d[\"metadata\"])\n",
    "    for d in data_dict\n",
    "]\n",
    "\n",
    "# Split each document into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "chunked_docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4460d",
   "metadata": {},
   "source": [
    "Embed and Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f249e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the embedding model -- subject to change... may need GPUs\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create FAISS vector store from chunked docs\n",
    "vector_store = Annoy.from_documents(chunked_docs, embedding_model)\n",
    "\n",
    "# Optionally save to disk\n",
    "vector_store.save_local(\"annoy_tax_code_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e0c705",
   "metadata": {},
   "source": [
    "Build RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8b952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ChatGPT as the LLM\n",
    "llm = GPT4All(model=\"/home/chandlernick/.local/share/nomic.ai/GPT4All/orca-mini-3b-gguf2-q4_0.gguf\", n_threads=4, backend=\"gptj\")\n",
    "\n",
    "# Reload vector store (if needed)\n",
    "# vector_store = FAISS.load_local(\"faiss_tax_code_index\", embedding_model)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", k=5)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"  # Or map_reduce for long documents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc15c34",
   "metadata": {},
   "source": [
    "Ask Tax Law Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "053c7f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14533/1559144912.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(query)\n",
      "Exception ignored on calling ctypes callback function: <function LLModel._callback_decoder.<locals>._raw_callback at 0x7c0de02992d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chandlernick/anaconda3/envs/general/lib/python3.10/site-packages/gpt4all/_pyllmodel.py\", line 573, in _raw_callback\n",
      "    def _raw_callback(token_id: int, response: bytes) -> bool:\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " The rental of a garage is generally considered a nontaxable activity, as it is considered an accessory use of the property and not a separate trade or business. However, if you have a mortgage on your property and are paying\n"
     ]
    }
   ],
   "source": [
    "query = \"Is the income from renting out my garage taxable under federal law?\"\n",
    "response = qa_chain.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
